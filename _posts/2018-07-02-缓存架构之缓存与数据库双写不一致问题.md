---
layout:     post
title:     缓存架构之缓存与数据库双写不一致问题 
subtitle:  
date:       2018-06-16
author:     Fogeeks
header-img: img/post-bg-re-vs-ng2.jpg
catalog:    true
tags:
    - Redis
    -并发安全
    -JMeter
---

# 缓存与数据库双写不一致问题 

#### 并发一致性问题分析
使用redis缓存过程当中，并发情况下很可能会出现缓存和数据库数据**不一致**的问题，一旦涉及实时性要求比较高的数据后都就会比较严重，数据库+缓存的模式再业务层面的实现基本思路是**先删除缓存，再去mysql查询相应给前台，采用懒加载的思想此时不去更新缓存，下次有读请求过来发现缓存没有数据就去mysql查询此时再刷新到redis缓存**。

但是在读写并发情况下，比如**电商库存操作**场景中，更新库存请求a要将某id=1的商品库存从3000更新到2999，他先删掉了redis缓存中的{id=1，productNum=3000}数据，正准备去数据库更新的时候，来了个此商品的读请求b，先去redis看下发现没有立马去MySQL查到事3000并刷新到缓存也是3000，这时候a更新数据库的请求才姗姗来迟吧mysql库存改成2999，于是就有了mysql2999redis3000，数据不一致了，后面读出来的全是脏数据，换句话说只要有读写并发
就可能会发生不一致问题。

#### 一致性问题解决方案
 
这个问题怎么解决，思路是**异步串行化**，同行数据不可并发读写，行，那就放到**阻塞队列**串行读写呗，根据key的hash值路由到不同的阻塞队列，每个队列的元素都是请求线程。

但是通常会有大量的读请求少量的写请求，读请求难道都要等前面请求执行才响应吗，不是，这里要过滤掉队列中对于同一商品连续的读请求，因为连续对于同一商品的**读请求是没有必要的反复在阻塞队列中执行**的，只有更新请求过来了之后，让队列花时间执行读请求才会有意义，实现方法是队列要维护一个ConcurrentHashMap数据结构{“productId”：““，”isWriteRequest“：”“}，代表队列中take出队的那个针对某商品的请求是否是写请求，若是那么就会覆盖map中的isWriteRequest=true，下一个读请求过来发现是true就知道我之前有人更新过数据，队列不能过滤我，得让我重新去缓存读取读不到就去mysql再刷新到缓存这样，后面的请求都得先等等了，读完之后isWriteRequest=false，下一个读请求过来看到就知道了，我前面兄弟是请求读数据的，缓存肯定是有数据的，我就不耽误后面兄弟执行任务了，把我过滤掉吧，这样就实现读请求过滤。

还有一个问题队列中读请求过来先查了redis没找着又查mysql还没查到，也就是所谓的空数据请求，这种请求也要过滤掉，事实上上一步维护的map无形中已经解决了这个问题，不管是否读到isWriteRequest始终是false，针对相同商品的连续的读请求直接过滤，知道有下一个写请求。

#### JMeter并发测试
上面的一致性解决方案到底有没有作用，对效率影响大不大，用JMeter测试下就知道了

读并发QPS测试（只使用两个队列，每个队列500容量，50个线程50次循环）

`读并发QPS测试聚合报告`
![读并发QPS测试聚合报告](https://github.com/forgeekscn/forgeekscn.github.io/blob/master/img/20180703-1.png?raw=true)
`读并发QPS测试图形报告`
![读并发QPS测试图形报告](https://github.com/forgeekscn/forgeekscn.github.io/blob/master/img/20180703-1.png?raw=true)
 
写并发QPS测试（只使用两个队列，每个队列500容量，70个线程70次循环）

`写并发QPS测试聚合报告`
![写并发QPS测试聚合报告](https://github.com/forgeekscn/forgeekscn.github.io/blob/master/img/20180703-3.png?raw=true)
`写并发QPS测试图形报告`
![写并发QPS测试图形报告](https://github.com/forgeekscn/forgeekscn.github.io/blob/master/img/20180703-4.png?raw=true)

从测试结果看读QPS有2k+写QPS有200+，要提升性能的话可以多初始化若干队列，队列容量大一些，就可以了。















